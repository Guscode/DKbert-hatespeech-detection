{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add libraries for data handling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#add libraries for BERT classification and evaluation\n",
    "from transformers import AutoTokenizer\n",
    "from sklearn.metrics import (accuracy_score, recall_score, precision_score, f1_score,\n",
    "                            classification_report,confusion_matrix)\n",
    "\n",
    "from transformers import TrainingArguments, Trainer\n",
    "import transformers as tf\n",
    "import torch\n",
    "  \n",
    "#Load tokenizer from huggingface\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Guscode/DKbert-hatespeech-detection\") \n",
    "\n",
    "#Load model from huggingface\n",
    "model = tf.AutoModelForSequenceClassification.from_pretrained(\"Guscode/DKbert-hatespeech-detection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read test set from OffensEval2020\n",
    "test_df = pd.read_csv( \n",
    "    \"Test_Hate.tsv\",\n",
    "    sep='\\t',\n",
    "    quotechar='\"',\n",
    "    error_bad_lines=False,\n",
    "    engine=\"python\",\n",
    "    encoding=\"UTF-8\"\n",
    ")\n",
    "test_df[\"label\"] = np.where(test_df[\"subtask_a\"] == \"NOT\", 0,1) #add binary label column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='42' max='42' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [42/42 00:20]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Class for converting tokenized text into a tensor which can be used for prediction\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels=None):\n",
    "        self.encodings = encodings #Define encodings\n",
    "        self.labels = labels #define labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()} #Define tensor item\n",
    "        if self.labels: #if labels are included, add to tensor\n",
    "            item[\"labels\"] = torch.tensor(self.labels[idx]) \n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings[\"input_ids\"])\n",
    "\n",
    "texts = list(test_df.tweet) #create list of strings\n",
    "texts_tokenized = tokenizer(texts, padding=True, truncation=True, max_length=128) #tokenize strings\n",
    "\n",
    "# Create torch dataset\n",
    "text_dataset = Dataset(texts_tokenized)\n",
    "\n",
    "text_trainer=Trainer(model) #create trainer from model\n",
    "raw_pred, _, _ = text_trainer.predict(text_dataset) #predict each string as hateful or not\n",
    " \n",
    "binary_preds = [np.argmax(pred) for pred in raw_pred] #Binarize raw predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.95       288\n",
      "           1       0.77      0.49      0.60        41\n",
      "\n",
      "    accuracy                           0.92       329\n",
      "   macro avg       0.85      0.73      0.78       329\n",
      "weighted avg       0.91      0.92      0.91       329\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[282,   6],\n",
       "       [ 21,  20]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(classification_report(test_df.label, ypred)) #Print classification report\n",
    "\n",
    "confusion_matrix(test_df.label, ypred) #print confusion matrix"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv101",
   "language": "python",
   "name": "cv101"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
