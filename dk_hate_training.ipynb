{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hatespeech_cds.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGva5og0McTW"
      },
      "source": [
        "#Load packages for data wrangling\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "#Load packages for finetuning classification model and saving it\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from simpletransformers.classification import ClassificationModel\n",
        "\n",
        "# specify GPU\n",
        "device = torch.device(\"cuda\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lkIhEj4KIViZ",
        "outputId": "16e58c3e-5133-48f5-fa13-87fa55634bc1"
      },
      "source": [
        "from google.colab import drive #Using google colab - connecting to google drive\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "#Loading training data\n",
        "train_df = pd.read_csv(\n",
        "    \"/content/drive/My Drive/hatespeech/Train_Hate.tsv\",\n",
        "    sep='\\t',\n",
        "    quotechar='\"',\n",
        "    error_bad_lines=False,\n",
        "    engine=\"python\",\n",
        "    encoding=\"UTF-8\"\n",
        ")\n",
        "\n",
        "#Loading testing data\n",
        "test_df = pd.read_csv(\n",
        "    \"/content/drive/My Drive/hatespeech/Test_Hate.tsv\",\n",
        "    sep='\\t',\n",
        "    quotechar='\"',\n",
        "    error_bad_lines=False,\n",
        "    engine=\"python\",\n",
        "    encoding=\"UTF-8\"\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0cYT6FuXcVm5"
      },
      "source": [
        "train_df = train_df.dropna() #Remove NAs\n",
        "test_df = test_df.dropna()#Remove NAs\n",
        "train_df[\"label\"] = np.where(train_df[\"subtask_a\"] == \"NOT\", 0,1) #Create binary label column\n",
        "test_df[\"label\"] = np.where(test_df[\"subtask_a\"] == \"NOT\", 0,1) #Create binary label column\n",
        "train_df = train_df[[\"tweet\", \"label\"]] #Select relevant columns\n",
        "test_df = test_df[[\"tweet\", \"label\"]] #Select relevant columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxKeLxQjde4q"
      },
      "source": [
        "# number of unique labels\n",
        "n_labels = len(train_df['label'].unique())\n",
        "\n",
        "# initialize the model with the right hyperparameters\n",
        "sent_model = ClassificationModel('bert',\"DJSammy/bert-base-danish-uncased_BotXO,ai\",\n",
        "                                 num_labels=n_labels, use_cuda=True,\n",
        "                                 args={'reprocess_input_data': True, 'overwrite_output_dir': True,\n",
        "                                       \"num_train_epochs\": 10, \"max_seq_length\": 128, \"train_batch_size\": 16,\n",
        "                                       \"learning_rate\": 1e-5})\n",
        "sent_model.train_model(train_df) #Train model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSCYBC-28ZNq"
      },
      "source": [
        "Model was saved in google drive and imported again to create a version that is executable using transformers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSy0PixJi46t"
      },
      "source": [
        "from transformers import TFBertForSequenceClassification\n",
        "model = TFBertForSequenceClassification.from_pretrained('/content/drive/My Drive/hatespeech/hater/', from_pt = True)\n",
        "model.save_pretrained('/content/drive/My Drive/hatespeech/hater/')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}